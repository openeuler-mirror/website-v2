---
title: Новости сообщества Ceph (в период с 17.01.2022 по 16.02.2022)  
date: 2022.02.23  
tags:  
    - Ceph  
    - Новости  
    - Pacific  
sig: ceph-sig  
archives: 2022.02  
author: rosinL  
summary: новости сообщества Ceph
---

# Новости сообщества Ceph (в период с 17.01.2022 по 16.02.2022)

## Отложенная конференция Cephalocon 2022

Конференция Cephalocon 2022, которая изначально планировалась на 5–7 апреля (6–8 апреля по пекинскому времени), отложена в связи с пандемией COVID-19. Новая дата мероприятия еще не объявлена. Доклады к конференции подготовлены и собраны в приведенной далее таблице. Подробную информацию см. в разделе [Расписание Cephalocon 2022](https://ceph2022.sched.com/). 

| Категория               | Тема доклада                                                 | Докладчик                             | Организация                                                  |
| ----------------------- | ------------------------------------------------------------ | ------------------------------------- | ------------------------------------------------------------ |
| RGW, производительность | [Оптимизация объектного хранилища RGW для рабочих нагрузок смешанного типа с помощью классификации памяти и разработки скрипта Lua](https://sched.co/w9FL) | Курт Брунс и Энтони Д'Атри            | Intel                                                        |
| RGW                     | [RGW:](https://sched.co/w9Fm)[ ](https://sched.co/w9Fm)[Что синхронизируем?](https://sched.co/w9Fm)[ ](https://sched.co/w9Fm)[Sync Info Provider:](https://sched.co/w9Fm)[ ](https://sched.co/w9Fm)[беглый обзор]() | Иегуда Садех-Вайнрауб                 | Red Hat                                                      |
| RGW                     | [RGW – непревзойденный фронтенд S3 для нескольких бэкендов:](https://sched.co/w9GJ)[ ](https://sched.co/w9GJ)[история реализации](https://sched.co/w9GJ) | Григорий Турецкий и Андрей Ткачук     | Seagate                                                      |
| RGW, S3select           | [S3select:](https://sched.co/w9GY)[ ](https://sched.co/w9GY)[Вычислительное хранилище в S3](https://sched.co/w9GY) | Галь Саломон и Гирджеш Рахория        | Red Hat                                                      |
| RGW                     | [Тестирование реализаций S3:](https://sched.co/w9Gh)[ ](https://sched.co/w9Gh)[RGW и не только](https://sched.co/w9Gh) | Робин Хью Джонсон                     | DigitalOcean                                                 |
| RGW                     | [Введение в интерфейс объектного хранилища контейнера (COSI) для ceph RGW](https://sched.co/w9Fs) | Джиффин Тони Тоттан                   | Red Hat                                                      |
| RGW                     | [RGW Zipper](https://sched.co/w9GD)                          | Даниэль Гриневич и Сумья Кодури       | Red Hat                                                      |
| Cephadm                 | [Блиц-доклад:](https://sched.co/w9EW)[ ](https://sched.co/w9EW)[введение в Cephadm](https://sched.co/w9EW) | Мелисса Ли                            | Red Hat                                                      |
| Dashboard               | [Dashboard:](https://sched.co/w9GP)[ ](https://sched.co/w9GP)[исследования в области централизованного ведения журнала в системе хранения данных Ceph Storage](https://sched.co/w9GP) | Гаурав Ситлани и Аашиш Шарма          | Red Hat                                                      |
| Dashboard               | [Эксплуатация системы хранения Ceph через панель управления Ceph Dashboard:](https://sched.co/w9F0)[ ](https://sched.co/w9F0)[вчера, сегодня и завтра]() | Эрнесто Пуэрта                        | Red Hat                                                      |
| Ceph, QoS, mClock       | [Оптимизация QoS в системе хранения Ceph для фоновых операций с помощью mClock](https://sched.co/w9Fv) | Шридхар Сешасайи                      | Red Hat                                                      |
| Ceph, PG                | [pgremapper:](https://sched.co/w9EZ)[ ](https://sched.co/w9EZ)[Сложности работы с кластером CRUSHing](https://sched.co/w9EZ) | Джошуа Баерген                        | DigitalOcean                                                 |
| Ceph, PG                | [Новый балансировщик рабочих нагрузок в Ceph](https://sched.co/w9Eo) | Джош Саломон и Лора Флорес            | Red Hat                                                      |
| Ceph, DPDK              | [Блиц-доклад:](https://sched.co/w9FO)[ ](https://sched.co/w9FO)[Разработка и отладка Ceph Messenger DPDkstack](https://sched.co/w9FO) | Чунсун Фэн                            | Huawei                                                       |
| Ceph, Windows           | [Ceph на ОС Windows](https://sched.co/w9Ei)                  | Алессандро Пилотти                    | Cloudbase Solutions                                          |
| Seastore                | [Что нового у Crimson и Seastore?](https://sched.co/w9FI)    | Самюэль Джаст                         | Red Hat                                                      |
| Seastore, Crimson       | [[Блиц-доклад]:](https://sched.co/w9FF)[ ](https://sched.co/w9FF)[Crimson глазами новичка](https://sched.co/w9FF) | Джозеф Савайя                         | Red Hat                                                      |
| Seastore                | [Интерпретация SeaStore путем профилирования производительности](https://sched.co/w9ET) | Инсинь Чэн и Тушар Гохад              | Intel                                                        |
| Bluestore               | [Ускорение операций устройства PMEM в BlueStore аппаратными методами разгрузки памяти](https://sched.co/w9F9) | Цзие Ян                               | Intel                                                        |
| Bluestore               | [Выявление ошибок, связанных с повреждением данных в BlueStore, в контейнерных кластерах Ceph](https://sched.co/w9Fj) | Сатору Такэути                        | Cybozu                                                       |
| Dev                     | [Отслеживаем неправильные контрольные суммы:](https://sched.co/w9Fd)[ ](https://sched.co/w9Fd)[турне по Ceph, TCMalloc и ядру Linux](https://sched.co/w9Fd) | Маурисио Фариа де Оливейра и Дэн Хилл | Canonical                                                    |
| Dev                     | [Блиц-доклад:](https://sched.co/w9Gt)[ ](https://sched.co/w9Gt)[оптимизация компоновки Ceph и автоматизация бэкпортирования с помощью Github Actions](https://sched.co/w9Gt) | Дипика Упадхьяй                       | Red Hat                                                      |
| Dev                     | [Контроль фатальных сбоев Ceph посредством телеметрии в действии](https://sched.co/w9Ec) | Яарит Хатука                          | Red Hat                                                      |
| Производительность      | [DisTRaC:](https://sched.co/w9Ef)[ ](https://sched.co/w9Ef)[ускорение высокопроизводительных вычислений в системах хранения временных данных](https://sched.co/w9Ef) | Габриэль Мейсон-Уильямс               | Rosalind Franklin Institute                                  |
| Производительность      | [Закладываем вычислительные мощности в вашу СХД](https://sched.co/w9Fg) | Федерико Люцифреди и Брэд Хаббард     | Red Hat                                                      |
| Производительность      | [Модификация Ceph для повышения производительности HPC](https://sched.co/w9Gb) | Даррен Сутхилл                        | CROIT                                                        |
| Производительность      | [Обработка более миллиарда запросов в день:](https://sched.co/w9FR)[ ](https://sched.co/w9FR)[производительностью кластера Ceph останется довольным каждый](https://sched.co/w9FR) | Джейн Чжу и Мэтью Леонард             | Bloomberg LP                                                 |
| Производительность      | [Извлечение уроков из проектов аппаратного ускорения работы приложений под Ceph](https://sched.co/w9G4) | Гарри Ричардсон и Лайонел Корбет      | SoftIron                                                     |
| Производительность      | [Актуальные разработки передовых SSD под Ceph](https://sched.co/w9GG) | Мёнвон О                              | Samsung Electronics                                          |
| Производительность      | [Поддержка интерфейса NVMe-over-Fabrics для Ceph](https://sched.co/w9GS) | Йонас Пфефферле, IBM и Скотт Петерсон | Intel                                                        |
| Безопасность            | [Знакомство с новой функцией шифрования образов RBD](https://sched.co/w9F3) | Ор Озери и Дэнни Харник               | IBM                                                          |
| Безопасность            | [Шифрование данных во время хранения в CephFS с помощью fscrypt](https://sched.co/w9Eu) | Джеффри Лейтон                        | Red Hat                                                      |
| Безопасность            | [Служба](https://ceph2022.sched.com/) [Secure Token Service в Ceph](https://sched.co/w9Ex) | Притха Шривастава                     | Red Hat                                                      |
| Безопасность            | [Безопасность данных и усиление защиты хранения в Rook и Ceph](https://sched.co/w9Fp) | Федерико Люцифред и Майкл Хакетт      | Red Hat                                                      |
| Применение Ceph         | [Оптимизация существующей крупной инфраструктуры Ceph с точки зрения непрерывности бизнеса:](https://sched.co/w9G7)[ ](https://sched.co/w9G7)[пример из практики](https://sched.co/w9G7) | Энрико Боч и Артур Оутенин-Шаландр    | CERN                                                         |
| Применение Ceph         | [Как мы эксплуатируем Ceph в нужном масштабе](https://sched.co/w9Fy) | Мэтт Вандермюлен                      | Digital Ocean                                                |
| Применение Ceph         | [Семинар по BoF:](https://sched.co/w9FC)[ ](https://sched.co/w9FC)[Ceph в научных вычислениях и крупных кластерах](https://sched.co/w9FC) | Кевин Хрпчек                          | Space Science \& Engineering Center, University of Wisconsin - Madison |
| Применение Ceph         | [Aquarium:](https://sched.co/w9Ge)[ ](https://sched.co/w9Ge)[как легко использовать устройства Ceph](https://sched.co/w9Ge) | Жоао Эдуардо Луис и Александра Сеттл  | SUSE                                                         |
| Применение Ceph         | [Расширение кластеров в Ceph:](https://sched.co/w9Gn)[ ](https://sched.co/w9Gn)[алгоритмы, примеры использования и улучшения](https://sched.co/w9Gn) | Грегори Фарнум                        | Red Hat                                                      |
| Применение Ceph         | [Как мы добавили к СХД Ceph 6 петабайт емкости и ни один пользователь не заметил...](https://sched.co/w9FX)[ ](https://sched.co/w9FX) | Джозеф Мундакал и Мэтью Леонард       | Bloomberg LP                                                 |
| Применение Ceph         | [Для чего мы построили систему телеметрии и сбора сообщений о работе всего кластера Ceph?](https://sched.co/w9FU) | Сяолинь Линь и Мэтью Леонард          | Bloomberg LP                                                 |
| Применение Ceph         | [Блиц-доклад.]()[ ](https://sched.co/w9Gk)[Ceph и 6G:](https://sched.co/w9Gk)[ ](https://sched.co/w9Gk)[а мы готовы к объемам данных, измеряемых в зеттабайтах?](https://sched.co/w9Gk) | Бабар Хан                             | Technical University Darmstadt                               |
| Применение Ceph         | [emails@ceph: хранение почтовых сообщений в кластере Ceph]() | Дэнни Аль-Гааф                        | Deutsche Telekom AG                                          |
| Применение Ceph         | [Блиц-доклад.]()[ ](https://sched.co/w9F6)[Ceph и QCOW2 — идеальный союз.](https://sched.co/w9F6)[ ](https://sched.co/w9F6)[Переходим от миграции в реальном времени к дифференцированным мгновенным снимкам](https://sched.co/w9F6) | Эффи Офер                             | IBM                                                          |
| Применение Ceph         | [Блиц-доклад](https://sched.co/w9Gk)[:](https://sched.co/w9GM)[ ](https://sched.co/w9GM)[установка Ceph на Kubernetes с использованием Rook Operator и Helm](https://sched.co/w9GM) | Майк Петерсен                         | Platform9                                                    |
| Эталонное тестирование  | [Делая выводы:](https://sched.co/w9GA)[ ](https://sched.co/w9GA)[эталонное тестирование Ceph в нужном масштабе](https://sched.co/w9GA) | Шон Пас и Идо Пал                     | Red Hat                                                      |
| Эталонное тестирование  | [Знакомимся с Sibench:](https://sched.co/w9GV)[ ](https://sched.co/w9GV)[новый инструмент эталонного тестирования](https://sched.co/w9GA)[ с открытым исходным кодом, оптимизированный под Ceph](https://sched.co/w9GV) | Дэнни Абукалам                        | SoftIron                                                     |



## Слияние PR

В последнее время PR ориентированы на исправление ошибок. Далее приведены наиболее значительные изменения:

- mgr: отключено восстановление pg по умолчанию при вводе и выводе OSD. Функцию по необходимости можно включить вручную, чтобы уменьшить влияние на сервисный кластер. [pr#44588](https://github.com/ceph/ceph/pull/44588)
- osd: в дамп производительности демона ceph добавлена опция dump\_blocked\_ops\_count, которая позволяет быстро получить число заблокированных операций, уменьшая затраты ресурсов на операцию dump\_blocked\_ops. [pr#44780](https://github.com/ceph/ceph/pull/44780)
- rgw: добавлена ​​поддержка условного копирования с помощью интерфейса rgw s3 CopyObject. [pr#44678](https://github.com/ceph/ceph/pull/44678)
- rgw: исправлена ​​проблема, связанная с занятием большого объема памяти во время процесса radosgw-admin bucket chown. [pr#44357](https://github.com/ceph/ceph/pull/44357)
- rbd: к krbd добавлена ​​опция rxbounce, которая решает проблемы с ошибками CRC и ухудшением производительности при использовании образов в качестве блочных устройств системы Windows. [pr#44842](https://github.com/ceph/ceph/pull/44842)

## Свежие новости от разработчиков Ceph

Каждый модуль сообщества Ceph проводит регулярные совещания, на которых обсуждаются и решаются вопросы, связанные с текущим прогрессом разработки. Видео совещаний выгружаются на [YouTube](https://www.youtube.com/channel/UCno-Fry25FJ7B4RycCxOtfw/videos). Наиболее важные совещания: 

| Совещание                                                    | Описание                                  | Частота           |
| ------------------------------------------------------------ | ----------------------------------------- | ----------------- |
| Еженедельное совещание по вопросам Crimson SeaStore OSD      | Разработка Crimson и SeaStore             | Еженедельно       |
| Совещание по вопросам оркестрации Ceph                       | Разработка управляющего модуля Ceph (mgr) | Еженедельно       |
| Совещание по вопросам Ceph DocUBetter                        | Оптимизация документов                    | Каждые две недели |
| Совещание по вопросам производительности Ceph                | Оптимизация производительности Ceph       | Каждые две недели |
| Ежемесячное совещание разработчиков Ceph                     | Разработчики Ceph                         | Ежемесячно        |
| Совещание по вопросам тестирования Ceph                      | Верификация и выпуск версий               | Ежемесячно        |
| Совещание группы пользователей Ceph, ведущие научную деятельность | Научные вычисления Ceph                   | Нерегулярно       |
| Совещание руководящей группы Ceph                            | Руководящий состав Ceph                   | Еженедельно       |

В последнее время сообщество уделяет большое внимание приостановленным тестам и верификации версии Quincy. На совещаниях обсуждаются следующие темы:

- В тесте версии Quincy производительность чтения соответствует ожиданиям, однако производительность записи в некоторых сценариях ухудшается. Производительность могут улучшить 4k min\_alloc\_size и bluestore allocator.
- По мере увеличения масштаба omap производительность итератора omap\_iterator приводит к большому числу операций slow\_ops или даже к отсутствию ответа. В раздел [проблемы](https://tracker.ceph.com/issues/53926) вносятся результаты испытаний двух режимов сжатия. Если сжатие запускается вручную, восстановить задержку до прежнего уровня невозможно. Для решение этой проблемы в Rocksdb предлагается функция [периодического сжатия и TTL](https://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide#periodic-and-ttl-compaction). После ее включения задержку можно будет восстановить до прежнего уровня.
- Для эталонного инструмента Ceph Benchmark Tool (CBT) выполнено слияние большого числа PR с упором на управление ресурсами памяти в сценариях тестирования OSD в крупномасштабной среде и параллельного тестирования в многоклиентской среде.